---
title:  interview note
layout: post
categories: 程序员
tags: 程序员 职场
excerpt: 
---

# 1. introduction
面试官你好， 我在18年毕业于华南理工大学电子科学专业。  
毕业后第一份工作是在华为， 在华为从事过数据库、加速库、汇编语言转换工具的开发。  
21年转到蚂蚁集团，从事OceanBase数据库多模特性的开发。
22年底转到大岩资本，主要负责量化交易系统的开发，以及订单簿重建相关的开发。

介绍项目经历：  
项目的描述，职责，结果  
GIS开发主要是针对外部客户使用到空间数据类型的项目，满足他们的需求。我在其中主要负责底层类型系统以及索引构建和查询的工作， 也包括部分表达式的开发。    
我针对存储格式设计了迭代器来适配Boost库， 使得存储格式无需转化成std::vector就可以用来计算，提高了计算的效率。  
我通过引入google-s2库，将空间数据切分成多个cellID，将二维的无序的空间数据转换成了一维的有序索引， 从而可以复用原来b+树的数据结构， 很大程度减少了开发工作量。  
在JSON项目中我主要负责表达式的开发，开发并测试13个json表达式， 上线后功能稳定。    
接下来简单讲一下在华为的项目。  
在opengauss项目中，我主要负责针对部分算力有限场景如边缘计算、PC用户等场景，对opengauss数据库进行小型化裁剪， 减少其在内存、磁盘、CPU等的占用。    
在汇编翻译项目中，主要是设计并实现一个工具实现x86汇编语言到arm平台的迁移， 主要的技术栈是llvm编译器， 我主要负责的工作是前期方案的选型、调研，以及后期指令语义的开发和性能优化。  
在弱内存序检测工具项目中， 这个项目主要是自动检测软件从x86架构到arm架构下迁移过程中暴露的弱内存序问题， 我主要负责的工作是前期方案的预研，经初步评估后只有通过形式化建模验证才能解决这个问题，需要较深的数学建模知识，后面转型成预研项目移交给公司剑桥研究所继续开发。 在这个项目中我们总结了很多迁移案例开放到鲲鹏社区给客户使用。 在预研过程中深入学习了perfbook， 对并行编程有了更深的理解。    
在加速库项目中，我完成strcpy/strlen等字符串接口的优化目标，使用NEON指令，结合循环展开、指令重排布等优化方式，在128字节以上性能平均提升10+%，将优化代码合入社区主干。    
在机顶盒项目中，主要负责linux内核驱动、生产软件相关的开发：    
• 高端机顶盒预研：适配摄像头、氛围灯等新外设的linux内核驱动。    
• 针对部分系统启动中的疑难问题定位，开发相关的DFX工具，使得启动阶段的系统信息、错误日 志能够及时记录下来，并且支持调试命令注入，有效支撑一线定位问题。    
• 针对生产中各局点的软件版本差异需手工部署导致生产效率低下的问题，开发组播升级过站管控功能，使得产品支持扫码自动完成组播升级， 拉通周边版本经理制定软件版本发布规范，有效提升生产效率和生产流程的可控性。    

# 2. behavior

## 2.1. 订单簿重建

简历内容：
公司需要拓展高频的业务，需要生产高频交易信号用于算法交易等业务。我通过使用逐笔行情进行订单簿重建，基于重建的订单簿构建一系列数据指标，驱动高频因子生产。通过对比交易所发布的快照数据，完整复现了交易所的价格笼子规则。通过交易所不同频道间、不同股票间的并发处理，结合无锁队列等优化，大幅提高重建的性能，平均每秒重建订单簿的时延降低到5ms以内，回测时构建一天的订单簿耗时在3分钟左右。投研反馈订单簿相关指标的信号强度高，对高频交易策略的效果显著。

逐字稿：

交易所订簿重建的开发主要是针对公司的高频业务，需要生产高频交易信号用于算法交易，以及驱动一些价量的因子生产。我在这里主要是负责订单簿的内部数据结构设计和开发，以及相关数据指标的开发。
这个项目的输入是逐笔委托和逐笔成交数据， 简单来说就是利用逐笔数据还原订单簿的内部数据结构，以接口的形式开放这个内部结构以供研究员使用，并且构造一些指标。

我先简单讲一下数据结构这一块。

问题和挑战： 在实盘中， 首先要考虑的是数据乱序问题。在实盘接受数据时候，委托和委托之间，委托和成交之间是可能乱序的，我们需要通过每个频道的bizindex来保证数据的顺序性和完整性。
解决方案： 所以在最前端有一个数据缓存的模块，用于接受逐笔委托和成交数据，然后再以bizindex的顺序把数据推到对应的频道队列中，然后再进行订单簿的重建。这个bizindex是在每个频道内单独编号的，所以每个频道都有一个这样的数据缓存，以及多个股票的数据结构，每个股票有一个完整的订单簿结构。

orderbook分成买方和卖方两个子book， 这两个子book是用一个模板类实现的，只要在内部通过一个买、卖的模板参数来区分即可，这样可以减少代码的重复和不必要的bug。每个子book内部有一系列不同价格档位的price bucket， 每个price bucket下存放了对应的订单队列。如果是下单，就往队列里添加订单；如果是撤单或者是执行，就从队列里删除或者修改订单。

写完这个基础结构之后，就是性能的优化。因为不同频道之间、股票之间都是独立的，所以可以并发处理，这里我使用了无锁队列来优化，使用了一个单生产者多消费者的无锁队列，频道内部多个worker并发，大幅提高了重建的性能。

结果：在回测中平均每秒重建订单簿的时延降低到5ms以内，回测时构建一天的订单簿耗时在3分钟左右。

------

下面再讲下测试这一块。

问题和挑战：实现了这个结构之后是怎么判断功能是否正确的？最开始是通过对比相同的TradeTime的快照数据，后面发现交易所的快照数据时间戳并不严格和逐笔数据对应，特别是一些创业板的股票，存在明显的偏移。因为从我们测试的结果来看，交易所在截取快照的时候是一定的顺序去遍历股票的，一些排在后面的股票有明显的延时。所以通过交易所时间戳去对比是不靠谱的。
解决方案：后面我修改了功能测试的方式，在每一个逐笔数据的处理之后，我都记录一个当前快照的摘要，例如委托买入、卖出总量等，然后在使用这个摘要去和交易所发布的行情去匹配。
结果： 功能测试全部通过，还发现上交所的部分快照数据有问题，统计量的更新(比如累计成交总量和委托买入总量)没有做到原子性。在注册制之后修复了这个问题。

问题和挑战：如何匹配深交所的价格笼子规则？深交所2020年对创业板股票实行了价格笼子规则，对于超过有效竞价范围的委托会暂存于交易主机；当价格波动到有效竞价范围时，交易所再取出申报进行撮合。
解决方案和结果：研读了深交所的价格笼子规则，再通过对比交易所发布的快照数据，完整复现了交易所的价格笼子规则。

具体有这些规则：
- 买卖创业板股票，连续竞价阶段限价申报的有效竞价范围，应当符合下列要求：
（一）买入申报价格不得高于买入基准价格的102%；
（二）卖出申报价格不得低于卖出基准价格的98%。
- 买卖无价格涨跌幅限制的股票，开盘集合竞价期间的有效申报价格范围为即时行情显示的前收盘价的 900%以内。
- [新股五日内]盘中临时停牌期间、收盘集合竞价期间的有效申报价格范围为最近成交价的上下 10%，收盘集合竞价在有效申报价格范围内进行撮合。
- 无价格涨跌幅限制的证券在集合竞价期间没有产生成交的，继续交易时，按下列方式调整有效竞价范围：
（一）有效竞价范围内的最高买入申报价高于即时行情显示的前收盘价或最近成交价，以最高买入申报价为基准调整有效竞价范围；
（二）有效竞价范围内的最低卖出申报价低于即时行情显示的前收盘价或最近成交价，以最低卖出申报价为基准调整有效竞价范围。
- 从笼子中取出委托单应保证其价格不优于对手方最优价格申报。

-----

再讲下数据指标的开发。

这些就相对比较简单了，对于算法交易这一块，主要是提供了一些对外暴露的接口，这些接口通过插件化的方式被调用，用于生产交易信号。
对于价量的因子生产，我生产了一些分钟级的k线指标，刻画一些交易行为。
比如说：
- 买N或卖N的撤单number, volume (abs(N)<=3)
- 本方买N和卖N的委托number，volume
- 主动（BS）成交中未能吃完对手方1档的number，volume，amount
- 从本方1变到2之后的撤单的number，volume

结果：投研反馈这些指标的信号强度很不错。

## 2.2. 交易系统开发

交易系统开发：当前不同家的券商交易柜台风格迥异，常需要交易员手动执行交易指令，交易延时高。我设计并开发了一个订单管理系统，抽象和规范化了接触过的所有主流柜台数据格式，实现了自动化交易。在服务端，我通过FastAPI实现了订单管理系统的Restful接口，方便投研下发交易指令。在券商交易端，我通过QuickFIX实现了适配于不同客户端的交易子程序。在服务端和交易端之间，通过Router来实现路由，并完成从http到fix的协议转换。总计对接了近20家不同券商客户端，实现了交易室交易账号的全自动化，大幅提高了交易效率。


背景和需求：这个项目的需求就是需要一个母单管理平台，对接各个券商下发交易指令。我们对接了很多不同家的券商，他们的交易柜台都不一样，之前的话需要交易员手动执行交易指令，交易延时高，且容易出错。

解决方案：我设计并开发了一个母单管理系统，抽象和规范化了接触过的所有主流柜台数据格式，实现了自动化交易。具体实现上的话，最前面是一个服务端，我通过FastAPI实现了母单管理系统的Restful接口，方便投研下发交易指令。在券商交易端，我通过c++的一个库QuickFIX实现了适配于不同客户端的交易程序。在服务端和交易端之间，通过Router来实现路由，并完成从http到fix的协议转换。

结果：
对接了近20家不同券商客户端，实现了交易室交易账号的全自动化，大幅提高了交易效率。

时延数据参考：

https://www.onixs.biz/insights/onixs-c-fix-engine-vs-quickfix-c-performance-comparison

## 2.3. GIS功能开发
空间数据类型的开发主要是针对外部客户例如地图公司、哈罗出行等需要处理海量空间数据的需求场景。我在其中主要负责底层类型系统构建、索引构建和查询、代价估计和索引选择的工作， 也包括部分表达式的开发。
我先简单讲一下类型系统这一块。
- 设计开发空间数据底层的类型系统，以支持配套的表达式计算， 支持存储格式直接适配Boost库， 显著优化计算效率。  
问题和挑战： 空间数据类型是有标准的协议，数据库里面用的一般是OGC定义的标准，它的类型有七种，包括点、线段、多边形等等。空间数据的计算往往比较复杂，比如判断复杂地理图形的相交、包含、距离等。实现工作量大但项目组人力有限。 引入boost-geometry库来做空间计算。 但是boost库有个比较麻烦的地方是需要绑定的类型提供类似于vector的RandomAccessIterator， 如果每次计算都把存储格式做反序列化，影响性能。  
解决方案： 针对存储格式设计迭代器来适配BG库， 使得存储格式可以基于迭代器来满足boost-geometry库的计算要求。  
结果： 无需引入额外的转化， 显著优化计算效率。  
- 构建倒排索引用于空间数据查询， 通过引入google-s2库，将空间数据切分成多个cellID，将二维的无序的空间数据转换成了一维的有序索引。  
问题和挑战： 在缺乏索引的时候查询的时候计算代价大， 空间数据是二维数据难以使用传统的方式来构建索引。当前业界主要有基于R树和基于四叉树的方案。R树方案对当前ob数据库中的b+树相关的逻辑侵入修改较大， 基于四叉树的方案可以通过引入希尔伯特曲线将二维数据转换成一维的有序编码，从而可以复用原来b+树的数据结构。  
解决方案： 通过引入google-s2库，将空间数据切分成多个cellID，将二维的无序的空间数据转换成了一维的有序索引。  
结果： 开发工作量较小，查询效率高， 在回表阶段也有基于MBR的过滤方式，有效结合了两种索引方案的优点。  
  
> 问题： 当前空间索引的实现是如何设计的？  
  
空间索引选用基于四叉树的空间划分方案。将空间平面按不同粒度划分为多层，每层上的每个网格按照希尔伯特曲线进行编码。使得每层上的每一个cell都是有序的。划分多层的意义在于单层网络无法平衡索引数量和查询性能。如网格划分太细，会导致每一个空间对象可能对应数百条索引。而网格划分太粗又会导致索引查询的精读太差， 返回的查询结果过多冗余。  
  
当前空间使用了s2库来进行空间划分，s2库将地球投影到六个平面，并将每个网格所属的平面、层级、希尔伯特序列都进行了编码，生成了可排序的空间索引cellid。空间索引的索引key直接使用s2库提供的cellid，进行空间索引查询时，会将空间关系的查询转化成cellid的范围查询，从而将二维的空间数据转换成了一维的索引数据，可以使用原来传统的b+索引来进行查询。  
  
> 问题： 当前的空间类型系统是如何设计的？  
  
按照openGis规范， 将空间数据分成点、线、多边形、multipoint、multilinestring、multipolygon和geometrycollection七种类型。 在这里以空间对象为基类，实现各个子类。  
  
> 问题： 为什么要使用google的s2库，这个库的作用是什么？  
  
s2库将地球投影到六个平面，并将每个网格所属的平面、层级、希尔伯特序列都进行了编码，生成了可排序的空间索引cellid。空间索引的索引key直接使用s2库提供的cellid，进行空间索引查询时，会将空间关系的查询转化成cellid的范围查询，从而将二维的空间数据转换成了一维的索引数据，可以使用原来传统的b+索引来进行查询。  
  
  
## 2.4. Json功能开发
针对json数据类型负责设计、开发对应的上层表达式， 兼容mysql的json访问接口。  
- 负责设计、开发并测试13个json表达式， 上线后功能稳定。  
- 重构底层类型系统的相关代码， 定义接口类统一内存和存储中的数据结构，提取Helper类消除冗余代码，优化表达式逻辑。  
  
> 问题： 为什么要重构代码？ 具体是如何重构代码的？  
  
json数据类型在代码中有两种存在的形式，一种是内存中的树状结构，另一种是用于存储的binary格式。  
As is:  
在重构之前，无法在表达式中屏蔽树和binary的差异。有较多的代码用于树和binary之间的转换。 并且存在大量对树和binary的类型的判断。  
  
To be:  
在重构之后，将树和binary统一继承于一个接口类， 表达式直接操作这一接口类即可。  
此外，在重复过程中发现了较多表达式之间的重复代码，所以提炼了相关的helper类以供表达式使用。后面在bug fix阶段发现这个helper类大有好处，有一些公共的bug，只要一个修改就同步到各个表达式了。  
  
> 问题： 能否举个例子说说开发表达式的工作？  
  
以json_contains为例：  
下面以json_contains为例简单说明下表达式开发的流程。  
JSON_CONTAINS(target, candidate[, path])。  
JSON_CONTAINS表达式用于检验一个候选JSON文档是否包含在目标JSON文档中。如果提供了路径参数则检验是否在目标内的特定路径上找到对应候选元素。  
其简要流程如下所示：  
分别parse目标、候选的json文档， 如果有输入path参数， 则从path中seek出对应的子元素作为目标json文档。  
接着对这两个文档做是否存在包含关系的判断。  
  
json_contains详细流程:  
对目标文档做分类讨论， 主要可以分成三种情况， 即目标文档属于OBJECT、ARRAY还是一个标量类型。  
如果是标量类型， 则直接做比较即可， 如果目标元素和候选元素相等则说明存在包含关系。  
如果是OBJECT类型， 首先判断候选文档是否类型相同， 如果不相同直接返回false。如果候选文档也是OBJECT类型， 则遍历候选文档中的每一个KV对， 判断key是否在目标文档存在， 若存在再递归判断两个相同的key对应的value是否是包含关系。 完成迭代后更新结果输出。  
如果是ARRAY类型， 统一将候选文档转成数组类型， 这样可以简化后续的代码。接着为两个数组创建排序索引数组提高后续搜索的效率， 接下来遍历候选元素的索引数组， 如果子元素是数组类型， 则我们可以通过排序索引数组快速在目标文档中找到数组类型的元素进行递归比较， 跳过类型不匹配的候选项，减少遍历范围。   
如果子元素不是数组类型， 则递归进行比较。迭代结束后更新结果输出。  
  
## 2.5. opengauss小型化
针对部分算力有限场景如边缘计算、PC用户等场景，对opengauss进行小型化裁剪， 减少其在内存、磁盘、CPU等的占用。  
  
• 快速使能opengauss集成至edgexFoundry平台中， 打通昇腾业务。  
• 通过修改将代码中的部分固定宏进行GUC参数化配置， 将空载下的驻留内存从647M降到267M。  
• 第三方依赖库优化， 对部分模块代码进行宏隔离，可通过configure配置是否启用该依赖库对应功能。  
• 修复WalWriter中的bug，将空载CPU占用率从60%下降至5%，使用UNLOGGED建表、PEB语句优化客户业务， 降低时延50%。  
  
  
> 我的小问题： 如何进行内存调优?  
  
- 分析内存视图  
- 在内存申请函数中添加dfx信息  
  
> 我的小问题： 内存优化后会影响性能吗？  
  
会的， 会影响某些业务单元，但是要评估客户是否会使用这个特性或者说是否会需要这个组件需要承担这么大的负载。  
- 在增量checkpoint中脏页队列大量占用内存  
减少脏页队列槽位会导致PageWriter的定期刷页更频繁， 增加了IO的波动， 影响性能。  
减小双写文件buffer的大小， 影响checkpoint中的双写速度。  
- 减少clog和csnlog分区数会影响日志的写入速度，但是在核数有限、内存有限的情况下并不需要这么多分区。  
- xlog相关  
    - xlog wal_buffer  
    在每次事务提交时，WAL 缓冲区的内容被写出到磁盘，因此极大的值不可能提供显著的收益。不过，把这个值设置为几个兆字节可以在一个繁忙的服务器（其中很多客户端会在同一时间提交）上提高写性能。  
    - WAL_INSERT_STATUS_ENTRIES  
    每条插入的状态数组， 取消xlog insert lock引入的数组， 在事务量大的时候使用该数组可以优化设计。  
    As is ： backend线程预留Wal的插入位置， 然后将生成的Wal复制到Walbuffer的对应预留位置上， 由于是并发拷贝， 每个backend线程拷贝完成的时机不一致。backend线程需要遍历所有的WalInsertLock来检查拷贝是否完成， 当WalInsertLock的数目越多，等待时间越长；当WalInsertLock的数目越少， xlog插入时锁的争抢就更激烈。  
    To be： 引入插入状态数组来替代xlog insert lock， 在复制日志到Wal buffer之前， 先预留此LSN对应的Wal插入位置，这样就不会和其他的xlog插入产生冲突。保留LSN后， agents就可以直接将Wal日志复制到LSN对应的Wal buffer中。在复制完毕后， 通过更新插入状态数组来报告复制进度。 插入状态数组由agents和Wal writer来更新， Wal writer在数组上循环查找复制完毕的连续数组条目， 然后Flush这些连续的条目。flush完毕后更新状态数组。新的agent就可以继续使用更新后的状态数组。  
    - Walwriter修改引入的bug  
    pthread_cond_wait函数的时钟参数没有正确设置， 相对时间vs绝对时间， 初始化时默认使用绝对时间， 但是在程序中是用相对时间来定时，导致直接返回等待， 造成了Walwriter的空转， 大量消耗CPU。  
- 并行redo相关优化  
    - 可以减少redo的线程数，减少BackendStatus的数量  
- 减少max_locks_per_transaction， 从而减小初始化Lock tables使用的共享空间  
  
> 我的小问题： 磁盘小型化怎么做？  
  
- 库的删减和整改  
- 数据文件中双写文件的减少  
双写文件用于替代两次checkpoint之间的整页写入功能，因为在增量checkpoint启用之后checkpoint的频率升高了， 如果将修改的页面记录到xlog， 会导致日志膨胀。所以引入双写文件， 每次页面下盘前， 先写到双写文件， 双写文件下盘后， 再向数据文件刷页。  
  
> 我的小问题： 时延优化手段是如和分析得到的？  
  
- redis使用rdb快照文件持久化， 属于unlogged的一种， 所以可以使用unlogged来建表  
- pgredis业务固定， 使用PBE来提高sql速度  
  
## 2.6. 汇编翻译
在这个项目中我们主要是基于开源的反编译框架去二次开发,  前期预研主要是做方案选型和验证。  

建立内容：

方案一：x86汇编转成C语言  
  
• 需求和目标分析：从200+开源项目筛选出4个关键项目，开发统计工具对其中涉及到的400+汇编文件进行分析，根据文件满足度目标确定需要支持的指令集。  
• 完成核心转换模块的设计和开发，根据从intel网站上爬取的信息，实现SIMD指令到intrinsic函数的自动转换框架，自动生成500+条指令的IR构造函数；设计测试用例自动生成框架，自动生成3000+针对指令的单元测试用例；优化后端生成模块，添加intrinsic相关的宏定义、头文件生成等特性，快速打通原型方案。 
https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#expand=27,2387,1879,1878,6123,6122,3864,4070,5322,4424,595,4432,301&text=_mm256_and_si256&ig_expand=306
• 提出一项发明专利：一种源文件模块接口的自动化适配方法(专利id:86939058)，用于汇编转换中的SIMD到intrinsic中的转换。  
  
  
方案二：x86汇编转arm汇编  
  
• 指令语义的开发:使用xed增强对指令操作数的支持，开发50条指令语义，指令单元测试和系统测试自动化率100% ，发现开源代码2个缺陷并提交patch至社区。  
• 指令语义的性能优化:对原指令语义中的类型和内存读写、逻辑运算操作进行向量化优化，使用intrinsic函数替换来优化部分 SIMD指令，优化后翻译得到的指令性能平均提升5倍以上。 对llvm pass进行优化， 保证IR的向量化不被pass转换为标量。   
• 进行项目知识库建设，主动分享了90+篇技术总结文档， 帮助2位新入职员工快速上手项目。  
  
> 我的小问题： 说说你的专利  
  
将汇编转换中的SIMD到intrinsic中的转换使用映射自动替换， 这其实可以抽象成一个软件接口适配的方法，  当时我们部门在鼓励写专利， 然后就把它提炼成专利了。  
  
  
> 我的小问题： 从架构上分析两个方案的优劣是什么？  
  
retdec方案简介：  
bin -> |capstone| -> inst * -> |instruction semantic irbuilder| -> IR -> llvm2hll -> C language  
  
remill:  
① instruction semantic by C -> |clang| -> bc file  
② bin -> |dynist| -> cfg -> |intel-xed| ->  inst * -> |remill-intrinsic-gen| -> IR with intrinsic func  
③ IR with intrinsic func -> |optimization with bc file| -> IR -> |Assembler| -> asm file  
  
retdec的主要优点：  
- 文档比较全  
- 上手比较简单， 有python脚本集成了各种功能。  
  
Remill的主要优点：  
- 功能上： 指令开发效率高  
通过模板化编程来构造语义的基础算子， 在构造语义时只要根据类型重载算子即可。  
As is:   
在retdec中， `instruction semantic`的构建需要手动写IRBuilder函数， 每种指令对应一条IRBuilder函数；  
To be:  
在remill中， 通过一系列`Types`和对应的`Operators`来作为各种语义的基本算子， 通过模板化编程， 将指令语义构建为模板函数， 通过`Types`的重载生成各种不同的`Instruction Form`下的指令语义函数。  
  
- 单元测试用例添加便捷， 无需考虑输出  
As is:  
在retdec中， 在每个UT中构造输入数据，例如寄存器、内存状态等，对指令进行汇编后再反编译到IR， 执行指令语义后检查IR中的状态， 与预期的输出数据进行对比。输入输出数据都需要通过预设的宏来设定。  
  
To be：  
在remill中， 每个UT只需要考虑输入数据， 而且通过汇编文件写用例， 使用汇编语法就可以写用例。 测试框架会在真实机器上执行汇编文件， 保存机器状态到内存中；与被测试的转换后代码输出的机器状态进行对比， 来判断执行是否一直。 这样无需构造输出数据。   
  
- 性能上可以批量做向量化优化  
As is:  
在retdec中， 指令的性能全靠手写的IRBuilder函数， 而且存在不可避免的C到汇编的转换开销。  
  
To be:  
在remill中， 可以通过对语义的基本算子做向量化优化，可以大大提升性能；  
可以定义intrinsic函数在优化阶段进行bitcode替换， 将加速库团队的arm intrinsic集成进来， 集成其他团队的工作成果。  
  
  
## 2.7. 弱内存序工具
项目旨在自动检测软件从x86架构到arm架构下迁移过程中暴露的弱内存序问题，在该项目中大量阅读外文文献和技术博客，进行核心方案的预研和测试框架搭建，输出技术分析文章3篇，读书笔记1篇。   
  
项目难度过大， 经初步评估后只有通过形式化建模验证才能解决，需要较深的数学建模知识， 后面由剑桥研究所继续做技术验证。  
在这个项目中阅读了perfbook， 对并行编程有了更深的理解。  
  
## 2.8. 加速库
完成strcpy/strlen/strnlen接口的优化目标，使用NEON指令，结合循环展开、指令重排布等优化方式，在128字节以上性能平均提升10+%，已将优化代码合入社区主干。  
  
优化手段主要包括：  
- 通过`uminv`指令优化核心主循环， 一次进行16字节的判空  
- 通过`loop unroll`优化核心主循环， 减少跳转， 提高大字节下的性能表现  
- 通过指令重排布解决芯片分支预测失败的bug  
  
## 2.9. 机顶盒
主要进行机顶盒linux内核开发：  
  
• 高端机顶盒预研：适配摄像头、氛围灯等新外设的linux内核驱动。  
• 针对部分系统启动中的疑难问题定位，开发相关的DFX工具，使得启动阶段的系统信息、错误日志能够及时记录下来，并且支持调试命令注入，有效支撑一线定位问题。  
• 针对生产中各局点的软件版本差异需手工部署导致生产效率低下的问题，开发组播升级过站管控功能，使得产品支持扫码自动完成组播升级， 拉通周边版本经理制定软件版本发布规范，有效提升生产效率和生产流程的可控性。  
