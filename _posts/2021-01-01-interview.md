
---
title:  interview note
layout: post
categories: 职场
tags: 职场
excerpt: sample
---

# 1. introduction  
面试官你好， 我在18年毕业于华南理工大学电子科学专业。  
毕业后第一份工作是在华为， 在华为从事过数据库、加速库、基于LLVM的x86汇编转换工具的开发。  
21年8月转到了蚂蚁集团，从事OceanBase数据库的开发。最近的工作主要是负责oceanbase数据库中的多模的特性开发， 添加Json、Gis空间数据类型以及对应的表达式的开发。  

介绍项目经历：  
项目的描述，职责，结果  
GIS开发主要是针对外部需要使用到空间数据类型的项目，满足他们的需求。我在其中主要负责底层类型系统以及索引构建和查询的工作， 也包括部分表达式的开发。    
我针对存储格式设计了迭代器来适配Boost库， 使得存储格式无需转化成std::vector就可以用来计算，提高了计算的效率。  
我通过引入google-s2库，将空间数据切分成多个cellID，将二维的无序的空间数据转换成了一维的有序索引， 从而可以复用原来b+树的数据结构， 很大程度减少了开发工作量。  
在JSON项目中我主要负责表达式的开发，开发并测试13个json表达式， 上线后功能稳定。    
接下来简单讲一下在华为的项目。  
在opengauss项目中，我主要负责针对部分算力有限场景如边缘计算、PC用户等场景，对opengauss数据库进行小型化裁剪， 减少其在内存、磁盘、CPU等的占用。    
在汇编翻译项目中，主要是设计并实现一个工具实现x86汇编语言到arm平台的迁移， 主要的技术栈是llvm编译器， 我主要负责的工作是前期方案的选型、调研，以及后期指令语义的开发和性能优化。  
在弱内存序检测工具项目中， 这个项目主要是自动检测软件从x86架构到arm架构下迁移过程中暴露的弱内存序问题， 我主要负责的工作是前期方案的预研，经初步评估后只有通过形式化建模验证才能解决这个问题，需要较深的数学建模知识，后面转型成预研项目移交给公司剑桥研究所继续开发。 在这个项目中我们总结了很多迁移案例开放到鲲鹏社区给客户使用。 在预研过程中深入学习了perfbook， 对并行编程有了更深的理解。    
在加速库项目中，我完成strcpy/strlen等字符串接口的优化目标，使用NEON指令，结合循环展开、指令重排布等优化方式，在128字节以上性能平均提升10+%，将优化代码合入社区主干。    
在机顶盒项目中，主要负责linux内核驱动、生产软件相关的开发：    
• 高端机顶盒预研：适配摄像头、氛围灯等新外设的linux内核驱动。    
• 针对部分系统启动中的疑难问题定位，开发相关的DFX工具，使得启动阶段的系统信息、错误日志能够及时记录下来，并且支持调试命令注入，有效支撑一线定位问题。    
• 针对生产中各局点的软件版本差异需手工部署导致生产效率低下的问题，开发组播升级过站管控功能，使得产品支持扫码自动完成组播升级， 拉通周边版本经理制定软件版本发布规范，有效提升生产效率和生产流程的可控性。    
  

# 2. behavior  
## 2.1. GIS功能开发  
针对空间数据类型，构建了底层的类型系统以及配套的空间索引查询能力。  
- 设计开发空间数据底层的类型系统，以支持配套的表达式计算， 支持存储格式直接适配Boost的地理库， 显著优化计算效率。  
问题和挑战： 空间数据计算复杂， 实现工作量大但项目组人力有限。 引入boost-geometry库来做空间计算。 boost库需要类型提供vector的能力， 如果统一把存储格式parse成vector的代价比较大，影响性能。  
解决方案： 针对存储格式设计迭代器来适配BG库， 使得存储格式可以基于迭代器来满足boost-geometry库的计算要求。  
结果： 无需引入额外的转化， 显著优化计算效率。  
- 构建倒排索引用于空间数据查询， 通过引入google-s2库，将空间数据切分成多个cellID，将二维的无序的空间数据转换成了一维的有序索引。  
问题和挑战： 在缺乏索引的时候查询的时候计算代价大， 空间数据是二维数据难以使用传统的方式来构建索引。当前业界主要有基于R树和基于四叉树的方案。R树方案对当前ob数据库中的b+树相关的逻辑侵入修改较大， 基于四叉树的方案可以通过引入希尔伯特曲线将二维数据转换成一维的有序编码，从而可以复用原来b+树的数据结构。  
解决方案： 通过引入google-s2库，将空间数据切分成多个cellID，将二维的无序的空间数据转换成了一维的有序索引。  
结果： 开发工作量较小，查询效率高， 在回表阶段也有基于MBR的过滤方式，有效结合了两种索引方案的优点。  
  
> 问题： 当前空间索引的实现是如何设计的？  
  
空间索引选用基于四叉树的空间划分方案。将空间平面按不同粒度划分为多层，每层上的每个网格按照希尔伯特曲线进行编码。使得每层上的每一个cell都是有序的。划分多层的意义在于单层网络无法平衡索引数量和查询性能。如网格划分太细，会导致每一个空间对象可能对应数百条索引。而网格划分太粗又会导致索引查询的精读太差， 返回的查询结果过多冗余。  
  
当前空间使用了s2库来进行空间划分，s2库将地球投影到六个平面，并将每个网格所属的平面、层级、希尔伯特序列都进行了编码，生成了可排序的空间索引cellid。空间索引的索引key直接使用s2库提供的cellid，进行空间索引查询时，会将空间关系的查询转化成cellid的范围查询，从而将二维的空间数据转换成了一维的索引数据，可以使用原来传统的b+索引来进行查询。  
  
> 问题： 当前的空间类型系统是如何设计的？  
  
按照openGis规范， 将空间数据分成点、线、多边形、multipoint、multilinestring、multipolygon和geometrycollection七种类型。 在这里以空间对象为基类，实现各个子类。  
  
> 问题： 为什么要使用google的s2库，这个库的作用是什么？  
  
s2库将地球投影到六个平面，并将每个网格所属的平面、层级、希尔伯特序列都进行了编码，生成了可排序的空间索引cellid。空间索引的索引key直接使用s2库提供的cellid，进行空间索引查询时，会将空间关系的查询转化成cellid的范围查询，从而将二维的空间数据转换成了一维的索引数据，可以使用原来传统的b+索引来进行查询。  
  
  
## 2.2. Json功能开发  
针对json数据类型负责设计、开发对应的上层表达式， 兼容mysql的json访问接口。  
- 负责设计、开发并测试13个json表达式， 上线后功能稳定。  
- 重构底层类型系统的相关代码， 定义接口类统一内存和存储中的数据结构，提取Helper类消除冗余代码，优化表达式逻辑。  
  
> 问题： 为什么要重构代码？ 具体是如何重构代码的？  
  
json数据类型在代码中有两种存在的形式，一种是内存中的树状结构，另一种是用于存储的binary格式。  
As is:  
在重构之前，无法在表达式中屏蔽树和binary的差异。有较多的代码用于树和binary之间的转换。 并且存在大量对树和binary的类型的判断。  
  
To be:  
在重构之后，将树和binary统一继承于一个接口类， 表达式直接操作这一接口类即可。  
此外，在重复过程中发现了较多表达式之间的重复代码，所以提炼了相关的helper类以供表达式使用。后面在bug fix阶段发现这个helper类大有好处，有一些公共的bug，只要一个修改就同步到各个表达式了。  
  
> 问题： 能否举个例子说说开发表达式的工作？  
  
以json_contains为例：  
下面以json_contains为例简单说明下表达式开发的流程。  
JSON_CONTAINS(target, candidate[, path])。  
JSON_CONTAINS表达式用于检验一个候选JSON文档是否包含在目标JSON文档中。如果提供了路径参数则检验是否在目标内的特定路径上找到对应候选元素。  
其简要流程如下所示：  
分别parse目标、候选的json文档， 如果有输入path参数， 则从path中seek出对应的子元素作为目标json文档。  
接着对这两个文档做是否存在包含关系的判断。  
  
json_contains详细流程:  
对目标文档做分类讨论， 主要可以分成三种情况， 即目标文档属于OBJECT、ARRAY还是一个标量类型。  
如果是标量类型， 则直接做比较即可， 如果目标元素和候选元素相等则说明存在包含关系。  
如果是OBJECT类型， 首先判断候选文档是否类型相同， 如果不相同直接返回false。如果候选文档也是OBJECT类型， 则遍历候选文档中的每一个KV对， 判断key是否在目标文档存在， 若存在再递归判断两个相同的key对应的value是否是包含关系。 完成迭代后更新结果输出。  
如果是ARRAY类型， 统一将候选文档转成数组类型， 这样可以简化后续的代码。接着为两个数组创建排序索引数组提高后续搜索的效率， 接下来遍历候选元素的索引数组， 如果子元素是数组类型， 则我们可以通过排序索引数组快速在目标文档中找到数组类型的元素进行递归比较， 跳过类型不匹配的候选项，减少遍历范围。   
如果子元素不是数组类型， 则递归进行比较。迭代结束后更新结果输出。  
  
## 2.3. opengauss小型化  
针对部分算力有限场景如边缘计算、PC用户等场景，对opengauss进行小型化裁剪， 减少其在内存、磁盘、CPU等的占用。  
  
• 快速使能opengauss集成至edgexFoundry平台中， 打通昇腾业务。  
• 通过修改将代码中的部分固定宏进行GUC参数化配置， 将空载下的驻留内存从647M降到267M。  
• 第三方依赖库优化， 对部分模块代码进行宏隔离，可通过configure配置是否启用该依赖库对应功能。  
• 修复WalWriter中的bug，将空载CPU占用率从60%下降至5%，使用UNLOGGED建表、PEB语句优化客户业务， 降低时延50%。  
  
  
> 我的小问题： 如何进行内存调优?  
  
- 分析内存视图  
- 在内存申请函数中添加dfx信息  
  
> 我的小问题： 内存优化后会影响性能吗？  
  
会的， 会影响某些业务单元，但是要评估客户是否会使用这个特性或者说是否会需要这个组件需要承担这么大的负载。  
- 在增量checkpoint中脏页队列大量占用内存  
减少脏页队列槽位会导致PageWriter的定期刷页更频繁， 增加了IO的波动， 影响性能。  
减小双写文件buffer的大小， 影响checkpoint中的双写速度。  
- 减少clog和csnlog分区数会影响日志的写入速度，但是在核数有限、内存有限的情况下并不需要这么多分区。  
- xlog相关  
    - xlog wal_buffer  
    在每次事务提交时，WAL 缓冲区的内容被写出到磁盘，因此极大的值不可能提供显著的收益。不过，把这个值设置为几个兆字节可以在一个繁忙的服务器（其中很多客户端会在同一时间提交）上提高写性能。  
    - WAL_INSERT_STATUS_ENTRIES  
    每条插入的状态数组， 取消xlog insert lock引入的数组， 在事务量大的时候使用该数组可以优化设计。  
    As is ： backend线程预留Wal的插入位置， 然后将生成的Wal复制到Walbuffer的对应预留位置上， 由于是并发拷贝， 每个backend线程拷贝完成的时机不一致。backend线程需要遍历所有的WalInsertLock来检查拷贝是否完成， 当WalInsertLock的数目越多，等待时间越长；当WalInsertLock的数目越少， xlog插入时锁的争抢就更激烈。  
    To be： 引入插入状态数组来替代xlog insert lock， 在复制日志到Wal buffer之前， 先预留此LSN对应的Wal插入位置，这样就不会和其他的xlog插入产生冲突。保留LSN后， agents就可以直接将Wal日志复制到LSN对应的Wal buffer中。在复制完毕后， 通过更新插入状态数组来报告复制进度。 插入状态数组由agents和Wal writer来更新， Wal writer在数组上循环查找复制完毕的连续数组条目， 然后Flush这些连续的条目。flush完毕后更新状态数组。新的agent就可以继续使用更新后的状态数组。  
    - Walwriter修改引入的bug  
    pthread_cond_wait函数的时钟参数没有正确设置， 相对时间vs绝对时间， 初始化时默认使用绝对时间， 但是在程序中是用相对时间来定时，导致直接返回等待， 造成了Walwriter的空转， 大量消耗CPU。  
- 并行redo相关优化  
    - 可以减少redo的线程数，减少BackendStatus的数量  
- 减少max_locks_per_transaction， 从而减小初始化Lock tables使用的共享空间  
  
> 我的小问题： 磁盘小型化怎么做？  
  
- 库的删减和整改  
- 数据文件中双写文件的减少  
双写文件用于替代两次checkpoint之间的整页写入功能，因为在增量checkpoint启用之后checkpoint的频率升高了， 如果将修改的页面记录到xlog， 会导致日志膨胀。所以引入双写文件， 每次页面下盘前， 先写到双写文件， 双写文件下盘后， 再向数据文件刷页。  
  
> 我的小问题： 时延优化手段是如和分析得到的？  
  
- redis使用rdb快照文件持久化， 属于unlogged的一种， 所以可以使用unlogged来建表  
- pgredis业务固定， 使用PBE来提高sql速度  
  
## 2.4. 汇编翻译  
在这个项目中我们主要是基于开源的反编译框架去二次开发,  前期预研主要是做方案选型和验证。  
  
方案一：x86汇编转成C语言  
  
• 需求和目标分析：从200+开源项目筛选出4个关键项目，开发统计工具对其中涉及到的400+汇编文件进行分析，根据文件满足度目标确定需要支持的指令集。  
• 完成核心转换模块的设计和开发，根据从intel网站上爬取的信息，实现SIMD指令到intrinsic函数的自动转换框架，自动生成500+条指令的IR构造函数；设计测试用例自动生成框架，自动生成3000+针对指令的单元测试用例；优化后端生成模块，添加intrinsic相关的宏定义、头文件生成等特性，快速打通原型方案。  
• 提出一项发明专利：一种源文件模块接口的自动化适配方法(专利id:86939058)，用于汇编转换中的SIMD到intrinsic中的转换。  
  
  
方案二：x86汇编转arm汇编  
  
• 指令语义的开发:使用xed增强对指令操作数的支持，开发50条指令语义，指令单元测试和系统测试自动化率100% ，发现开源代码2个缺陷并提交patch至社区。  
• 指令语义的性能优化:对原指令语义中的类型和内存读写、逻辑运算操作进行向量化优化，使用intrinsic函数替换来优化部分 SIMD指令，优化后翻译得到的指令性能平均提升5倍以上。 对llvm pass进行优化， 保证IR的向量化不被pass转换为标量。   
• 进行项目知识库建设，主动分享了90+篇技术总结文档， 帮助2位新入职员工快速上手项目。  
  
> 我的小问题： 说说你的专利  
  
将汇编转换中的SIMD到intrinsic中的转换使用映射自动替换， 这其实可以抽象成一个软件接口适配的方法，  当时我们部门在鼓励写专利， 然后就把它提炼成专利了。  
  
  
> 我的小问题： 从架构上分析两个方案的优劣是什么？  
  
retdec方案简介：  
bin -> |capstone| -> inst * -> |instruction semantic irbuilder| -> IR -> llvm2hll -> C language  
  
remill:  
① instruction semantic by C -> |clang| -> bc file  
② bin -> |dynist| -> cfg -> |xed| ->  inst * -> |remill-intrinsic-gen| -> IR with intrinsic func  
③ IR with intrinsic func -> |optimization with bc file| -> IR -> |Assembler| -> asm file  
  
retdec的主要优点：  
- 文档比较全  
- 上手比较简单， 有python脚本集成了各种功能。  
  
Remill的主要优点：  
- 功能上： 指令开发效率高  
通过模板化编程来构造语义的基础算子， 在构造语义时只要根据类型重载算子即可。  
As is:   
在retdec中， `instruction semantic`的构建需要手动写IRBuilder函数， 每种指令对应一条IRBuilder函数；  
To be:  
在remill中， 通过一系列`Types`和对应的`Operators`来作为各种语义的基本算子， 通过模板化编程， 将指令语义构建为模板函数， 通过`Types`的重载生成各种不同的`Instruction Form`下的指令语义函数。  
  
- 单元测试用例添加便捷， 无需考虑输出  
As is:  
在retdec中， 在每个UT中构造输入数据，例如寄存器、内存状态等，对指令进行汇编后再反编译到IR， 执行指令语义后检查IR中的状态， 与预期的输出数据进行对比。输入输出数据都需要通过预设的宏来设定。  
  
To be：  
在remill中， 每个UT只需要考虑输入数据， 而且通过汇编文件写用例， 使用汇编语法就可以写用例。 测试框架会在真实机器上执行汇编文件， 保存机器状态到内存中；与被测试的转换后代码输出的机器状态进行对比， 来判断执行是否一直。 这样无需构造输出数据。   
  
- 性能上可以批量做向量化优化  
As is:  
在retdec中， 指令的性能全靠手写的IRBuilder函数， 而且存在不可避免的C到汇编的转换开销。  
  
To be:  
在remill中， 可以通过对语义的基本算子做向量化优化，可以大大提升性能；  
可以定义intrinsic函数在优化阶段进行bitcode替换， 将加速库团队的arm intrinsic集成进来， 集成其他团队的工作成果。  
  
  
## 2.5. 弱内存序工具  
项目旨在自动检测软件从x86架构到arm架构下迁移过程中暴露的弱内存序问题，在该项目中大量阅读外文文献和技术博客，进行核心方案的预研和测试框架搭建，输出技术分析文章3篇，读书笔记1篇。   
  
项目难度过大， 经初步评估后只有通过形式化建模验证才能解决，需要较深的数学建模知识， 后面由剑桥研究所继续做技术验证。  
在这个项目中阅读了perfbook， 对并行编程有了更深的理解。  
  
## 2.6. 加速库  
完成strcpy/strlen/strnlen接口的优化目标，使用NEON指令，结合循环展开、指令重排布等优化方式，在128字节以上性能平均提升10+%，已将优化代码合入社区主干。  
  
优化手段主要包括：  
- 通过`uminv`指令优化核心主循环， 一次进行16字节的判空  
- 通过`loop unroll`优化核心主循环， 减少跳转， 提高大字节下的性能表现  
- 通过指令重排布解决芯片分支预测失败的bug  
  
## 2.7. 机顶盒  
主要进行机顶盒linux内核开发：  
  
• 高端机顶盒预研：适配摄像头、氛围灯等新外设的linux内核驱动。  
• 针对部分系统启动中的疑难问题定位，开发相关的DFX工具，使得启动阶段的系统信息、错误日志能够及时记录下来，并且支持调试命令注入，有效支撑一线定位问题。  
• 针对生产中各局点的软件版本差异需手工部署导致生产效率低下的问题，开发组播升级过站管控功能，使得产品支持扫码自动完成组播升级， 拉通周边版本经理制定软件版本发布规范，有效提升生产效率和生产流程的可控性。  
  
  
